{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB-jitxQsQuj"
   },
   "source": [
    "# DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection\n",
    "\n",
    "https://github.com/IDEA-Research/DINO\n",
    "\n",
    "[Papers With Code Link](https://paperswithcode.com/paper/focal-modulation-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RgFU4gGiroou"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet pylance duckdb torch torchvision transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bj2GEDTCvW1D"
   },
   "source": [
    "## Build and install [DINO]() Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCFwh-_AtGqR",
    "outputId": "da37e6ce-540e-4c6e-d50f-c7f0b7524cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "/home/lei/work/lance/python/notebooks/DINO\n",
      "/home/lei/work/lance/python/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "/home/lei/work/lance/python/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.8) has a minor version mismatch with the version that was used to compile PyTorch (11.7). Most likely this shouldn't be a problem.\n",
      "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "/home/lei/work/lance/python/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:397: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
      "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "/home/lei/work/lance/python/venv/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/lei/work/lance/python/venv/lib/python3.10/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n"
     ]
    }
   ],
   "source": [
    "!git -C DINO pull || git clone https://github.com/IDEACVR/DINO\n",
    "%cd DINO\n",
    "\n",
    "!pip install --quiet -r requirements.txt \\\n",
    "  && cd models/dino/ops \\\n",
    "  && python setup.py -q build install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zL2g1T-lveXO",
    "outputId": "6eeec42b-75b9-4081-a906-e252d186144f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lei/work/lance/python/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lei/work/lance/python/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/lei/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446ef49f7dbf4429b3243a1abb63b38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See https://github.com/IDEA-Research/DINO/blob/main/inference_and_visualization.ipynb\n",
    "# for instruction to load model\n",
    "from util.slconfig import SLConfig\n",
    "from main import build_model_main\n",
    "model_config_path = \"config/DINO/DINO_4scale.py\"\n",
    "\n",
    "args = SLConfig.fromfile(model_config_path) \n",
    "args.device = 'cuda' \n",
    "model, criterion, postprocessors = build_model_main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "27ah_AGcxHS5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: gsutil\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model_checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/work/lance/python/venv/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/work/lance/python/venv/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/work/lance/python/venv/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/model.pt'"
     ]
    }
   ],
   "source": [
    "# Downloads weights\n",
    "\n",
    "# Download DINO-4scale weights\n",
    "! [[ -f /tmp/model.pt ]] || gsutil cp gs://eto-public/models/dino/checkpoint0033_4scale.pth /tmp/model.pt\n",
    "import torch\n",
    "model_checkpoint_path = \"/tmp/model.pt\"\n",
    "checkpoint = torch.load(model_checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "_ = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxfGl-V6xeqS"
   },
   "source": [
    "## Prepare COCO validation dataset to [Lance](https://github.com/eto-ai/lance) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LUEmksJKIP4b",
    "outputId": "1a2e3983-653f-4c15-beab-cd466b3278a7"
   },
   "outputs": [],
   "source": [
    "! [[ -f annotations/instances_val2017.json ]] || ( \\\n",
    "  wget -O /tmp/annotations.zip http://images.cocodataset.org/annotations/annotations_trainval2017.zip && \\\n",
    "  unzip -o -qq /tmp/annotations.zip && rm annotations.zip \\\n",
    ")\n",
    "! [[ -d val2017/ ]] || ( \\\n",
    "  wget -O /tmp/val2017.zip http://images.cocodataset.org/zips/val2017.zip && \\\n",
    "  unzip -o -qq /tmp/val2017.zip && \\\n",
    "  rm val2017.zip )\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "with open(\"annotations/instances_val2017.json\") as fobj:\n",
    "  data = json.load(fobj)\n",
    "\n",
    "print(data.keys())\n",
    "images_df = (\n",
    "    pd\n",
    "    .DataFrame(data=data[\"images\"])\n",
    "    .rename(columns={\"id\": \"image_id\"}) \n",
    ")\n",
    "\n",
    "print(images_df)\n",
    "annos_df = (pd.DataFrame(data=data[\"annotations\"]))\n",
    "annos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "p66vbzcW5uhO",
    "outputId": "2dc99199-6200-4083-c362-f9a32846d40e"
   },
   "outputs": [],
   "source": [
    "from lance.pytorch import Dataset\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(400),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "dataset = Dataset(\n",
    "    \"s3://eto-public/datasets/coco/coco.lance\",\n",
    "    columns=[\"image\", \"split\", \"image_id\"],\n",
    "    # mode=\"batch\",\n",
    "    batch_size=8)\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "  for batch in dataset:\n",
    "    image_id = batch[2].cpu().item()\n",
    "    imgs = [transform(batch[0]).cuda()]\n",
    "    # print(batch, batch.shape)\n",
    "    output = model(imgs)\n",
    "    output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]\n",
    "    mask = output[\"scores\"] > threshold\n",
    "    pred = {\n",
    "        \"image_id\": image_id,\n",
    "        \"boxes\": output[\"boxes\"][mask].cpu().numpy(),\n",
    "        \"labels\": output[\"labels\"][mask].cpu().numpy(),\n",
    "        \"scores\": output[\"scores\"][mask].cpu().numpy(),\n",
    "    }\n",
    "    del output\n",
    "    results.append(pred)\n",
    "\n",
    "df = pd.DataFrame(data=results)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMvmDFMzPhOs4C3bt8kjhCr",
   "collapsed_sections": [
    "bj2GEDTCvW1D"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
