{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bj2GEDTCvW1D"
      ],
      "authorship_tag": "ABX9TyMvmDFMzPhOs4C3bt8kjhCr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection\n",
        "\n",
        "https://github.com/IDEA-Research/DINO\n",
        "\n",
        "[Papers With Code Link](https://paperswithcode.com/paper/focal-modulation-networks)"
      ],
      "metadata": {
        "id": "XB-jitxQsQuj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RgFU4gGiroou"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet pylance duckdb torch torchvision transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and install [DINO]() Model"
      ],
      "metadata": {
        "id": "bj2GEDTCvW1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git -C DINO pull || git clone https://github.com/IDEACVR/DINO\n",
        "%cd DINO\n",
        "\n",
        "!pip install --quiet -r requirements.txt \\\n",
        "  && cd models/dino/ops \\\n",
        "  && python setup.py -q build install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCFwh-_AtGqR",
        "outputId": "da37e6ce-540e-4c6e-d50f-c7f0b7524cb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "/content/DINO\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:411: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:813: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.3). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-38: module references __file__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See https://github.com/IDEA-Research/DINO/blob/main/inference_and_visualization.ipynb\n",
        "# for instruction to load model\n",
        "from util.slconfig import SLConfig\n",
        "from main import build_model_main\n",
        "model_config_path = \"config/DINO/DINO_4scale.py\"\n",
        "\n",
        "args = SLConfig.fromfile(model_config_path) \n",
        "args.device = 'cuda' \n",
        "model, criterion, postprocessors = build_model_main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL2g1T-lveXO",
        "outputId": "6eeec42b-75b9-4081-a906-e252d186144f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads weights\n",
        "\n",
        "# Download DINO-4scale weights\n",
        "! [[ -f /tmp/model.pt ]] || gsutil cp gs://eto-public/models/dino/checkpoint0033_4scale.pth /tmp/model.pt\n",
        "import torch\n",
        "model_checkpoint_path = \"/tmp/model.pt\"\n",
        "checkpoint = torch.load(model_checkpoint_path)\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "_ = model.cuda().eval()"
      ],
      "metadata": {
        "id": "27ah_AGcxHS5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare COCO validation dataset to [Lance](https://github.com/eto-ai/lance) format."
      ],
      "metadata": {
        "id": "xxfGl-V6xeqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! [[ -f annotations/instances_val2017.json ]] || ( \\\n",
        "  wget -O /tmp/annotations.zip http://images.cocodataset.org/annotations/annotations_trainval2017.zip && \\\n",
        "  unzip -o -qq /tmp/annotations.zip && rm annotations.zip \\\n",
        ")\n",
        "! [[ -d val2017/ ]] || ( \\\n",
        "  wget -O /tmp/val2017.zip http://images.cocodataset.org/zips/val2017.zip && \\\n",
        "  unzip -o -qq /tmp/val2017.zip && \\\n",
        "  rm val2017.zip )\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "with open(\"annotations/instances_val2017.json\") as fobj:\n",
        "  data = json.load(fobj)\n",
        "\n",
        "print(data.keys())\n",
        "images_df = (\n",
        "    pd\n",
        "    .DataFrame(data=data[\"images\"])\n",
        "    .rename(columns={\"id\": \"image_id\"}) \n",
        ")\n",
        "\n",
        "print(images_df)\n",
        "annos_df = (pd.DataFrame(data=data[\"annotations\"]))\n",
        "annos_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LUEmksJKIP4b",
        "outputId": "1a2e3983-653f-4c15-beab-cd466b3278a7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])\n",
            "      license         file_name  \\\n",
            "0           4  000000397133.jpg   \n",
            "1           1  000000037777.jpg   \n",
            "2           4  000000252219.jpg   \n",
            "3           1  000000087038.jpg   \n",
            "4           6  000000174482.jpg   \n",
            "...       ...               ...   \n",
            "4995        3  000000512403.jpg   \n",
            "4996        4  000000168974.jpg   \n",
            "4997        1  000000552775.jpg   \n",
            "4998        3  000000394940.jpg   \n",
            "4999        2  000000015335.jpg   \n",
            "\n",
            "                                               coco_url  height  width  \\\n",
            "0     http://images.cocodataset.org/val2017/00000039...     427    640   \n",
            "1     http://images.cocodataset.org/val2017/00000003...     230    352   \n",
            "2     http://images.cocodataset.org/val2017/00000025...     428    640   \n",
            "3     http://images.cocodataset.org/val2017/00000008...     480    640   \n",
            "4     http://images.cocodataset.org/val2017/00000017...     388    640   \n",
            "...                                                 ...     ...    ...   \n",
            "4995  http://images.cocodataset.org/val2017/00000051...     640    529   \n",
            "4996  http://images.cocodataset.org/val2017/00000016...     500    375   \n",
            "4997  http://images.cocodataset.org/val2017/00000055...     500    375   \n",
            "4998  http://images.cocodataset.org/val2017/00000039...     640    426   \n",
            "4999  http://images.cocodataset.org/val2017/00000001...     480    640   \n",
            "\n",
            "            date_captured                                         flickr_url  \\\n",
            "0     2013-11-14 17:02:52  http://farm7.staticflickr.com/6116/6255196340_...   \n",
            "1     2013-11-14 20:55:31  http://farm9.staticflickr.com/8429/7839199426_...   \n",
            "2     2013-11-14 22:32:02  http://farm4.staticflickr.com/3446/3232237447_...   \n",
            "3     2013-11-14 23:11:37  http://farm8.staticflickr.com/7355/8825114508_...   \n",
            "4     2013-11-14 23:16:55  http://farm8.staticflickr.com/7020/6478877255_...   \n",
            "...                   ...                                                ...   \n",
            "4995  2013-11-24 05:12:53  http://farm1.staticflickr.com/143/350452845_fa...   \n",
            "4996  2013-11-24 07:19:48  http://farm3.staticflickr.com/2360/2063838083_...   \n",
            "4997  2013-11-24 10:38:31  http://farm4.staticflickr.com/3136/3106037881_...   \n",
            "4998  2013-11-24 13:47:05  http://farm9.staticflickr.com/8227/8566023505_...   \n",
            "4999  2013-11-25 14:00:10  http://farm6.staticflickr.com/5533/10257288534...   \n",
            "\n",
            "      image_id  \n",
            "0       397133  \n",
            "1        37777  \n",
            "2       252219  \n",
            "3        87038  \n",
            "4       174482  \n",
            "...        ...  \n",
            "4995    512403  \n",
            "4996    168974  \n",
            "4997    552775  \n",
            "4998    394940  \n",
            "4999     15335  \n",
            "\n",
            "[5000 rows x 8 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            segmentation          area  \\\n",
              "0      [[510.66, 423.01, 511.72, 420.03, 510.45, 416....     702.10575   \n",
              "1      [[289.74, 443.39, 302.29, 445.32, 308.09, 427....   27718.47630   \n",
              "2      [[147.76, 396.11, 158.48, 355.91, 153.12, 347....   78969.31690   \n",
              "3      [[260.4, 231.26, 215.06, 274.01, 194.33, 307.6...  108316.66515   \n",
              "4      [[200.61, 253.97, 273.19, 318.49, 302.43, 336....   75864.53530   \n",
              "...                                                  ...           ...   \n",
              "36776  {'counts': [94823, 6, 473, 8, 471, 10, 469, 11...    3773.00000   \n",
              "36777  {'counts': [277, 2, 361, 9, 1, 17, 3, 17, 3, 8...  112181.00000   \n",
              "36778  {'counts': [2770, 6, 418, 8, 416, 10, 86, 6, 3...   47024.00000   \n",
              "36779  {'counts': [3912, 10, 363, 18, 356, 23, 301, 1...   27277.00000   \n",
              "36780  {'counts': [179, 27, 392, 41, 380, 51, 371, 59...  220834.00000   \n",
              "\n",
              "       iscrowd  image_id                              bbox  category_id  \\\n",
              "0            0    289343    [473.07, 395.93, 38.65, 28.67]           18   \n",
              "1            0     61471   [272.1, 200.23, 151.97, 279.77]           18   \n",
              "2            0    472375  [124.71, 196.18, 372.85, 356.81]           18   \n",
              "3            0    520301  [112.71, 154.82, 367.29, 479.35]           18   \n",
              "4            0    579321   [200.61, 89.65, 400.22, 251.02]           18   \n",
              "...        ...       ...                               ...          ...   \n",
              "36776        1     15517               [197, 248, 264, 45]            6   \n",
              "36777        1    439994                  [0, 0, 427, 458]            1   \n",
              "36778        1    117719                 [6, 75, 474, 263]           44   \n",
              "36779        1     50149                [10, 41, 403, 152]           52   \n",
              "36780        1    250282                 [0, 34, 639, 388]            1   \n",
              "\n",
              "                 id  \n",
              "0              1768  \n",
              "1              1773  \n",
              "2              2551  \n",
              "3              3186  \n",
              "4              3419  \n",
              "...             ...  \n",
              "36776  900600015517  \n",
              "36777  900100439994  \n",
              "36778  904400117719  \n",
              "36779  905200050149  \n",
              "36780  900100250282  \n",
              "\n",
              "[36781 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12b33253-597b-4864-97a9-4b7f17262f29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segmentation</th>\n",
              "      <th>area</th>\n",
              "      <th>iscrowd</th>\n",
              "      <th>image_id</th>\n",
              "      <th>bbox</th>\n",
              "      <th>category_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[510.66, 423.01, 511.72, 420.03, 510.45, 416....</td>\n",
              "      <td>702.10575</td>\n",
              "      <td>0</td>\n",
              "      <td>289343</td>\n",
              "      <td>[473.07, 395.93, 38.65, 28.67]</td>\n",
              "      <td>18</td>\n",
              "      <td>1768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[289.74, 443.39, 302.29, 445.32, 308.09, 427....</td>\n",
              "      <td>27718.47630</td>\n",
              "      <td>0</td>\n",
              "      <td>61471</td>\n",
              "      <td>[272.1, 200.23, 151.97, 279.77]</td>\n",
              "      <td>18</td>\n",
              "      <td>1773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[147.76, 396.11, 158.48, 355.91, 153.12, 347....</td>\n",
              "      <td>78969.31690</td>\n",
              "      <td>0</td>\n",
              "      <td>472375</td>\n",
              "      <td>[124.71, 196.18, 372.85, 356.81]</td>\n",
              "      <td>18</td>\n",
              "      <td>2551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[260.4, 231.26, 215.06, 274.01, 194.33, 307.6...</td>\n",
              "      <td>108316.66515</td>\n",
              "      <td>0</td>\n",
              "      <td>520301</td>\n",
              "      <td>[112.71, 154.82, 367.29, 479.35]</td>\n",
              "      <td>18</td>\n",
              "      <td>3186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[200.61, 253.97, 273.19, 318.49, 302.43, 336....</td>\n",
              "      <td>75864.53530</td>\n",
              "      <td>0</td>\n",
              "      <td>579321</td>\n",
              "      <td>[200.61, 89.65, 400.22, 251.02]</td>\n",
              "      <td>18</td>\n",
              "      <td>3419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36776</th>\n",
              "      <td>{'counts': [94823, 6, 473, 8, 471, 10, 469, 11...</td>\n",
              "      <td>3773.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>15517</td>\n",
              "      <td>[197, 248, 264, 45]</td>\n",
              "      <td>6</td>\n",
              "      <td>900600015517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36777</th>\n",
              "      <td>{'counts': [277, 2, 361, 9, 1, 17, 3, 17, 3, 8...</td>\n",
              "      <td>112181.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>439994</td>\n",
              "      <td>[0, 0, 427, 458]</td>\n",
              "      <td>1</td>\n",
              "      <td>900100439994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36778</th>\n",
              "      <td>{'counts': [2770, 6, 418, 8, 416, 10, 86, 6, 3...</td>\n",
              "      <td>47024.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>117719</td>\n",
              "      <td>[6, 75, 474, 263]</td>\n",
              "      <td>44</td>\n",
              "      <td>904400117719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36779</th>\n",
              "      <td>{'counts': [3912, 10, 363, 18, 356, 23, 301, 1...</td>\n",
              "      <td>27277.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>50149</td>\n",
              "      <td>[10, 41, 403, 152]</td>\n",
              "      <td>52</td>\n",
              "      <td>905200050149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36780</th>\n",
              "      <td>{'counts': [179, 27, 392, 41, 380, 51, 371, 59...</td>\n",
              "      <td>220834.00000</td>\n",
              "      <td>1</td>\n",
              "      <td>250282</td>\n",
              "      <td>[0, 34, 639, 388]</td>\n",
              "      <td>1</td>\n",
              "      <td>900100250282</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36781 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12b33253-597b-4864-97a9-4b7f17262f29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12b33253-597b-4864-97a9-4b7f17262f29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12b33253-597b-4864-97a9-4b7f17262f29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lance.pytorch import Dataset\n",
        "import torchvision.transforms as T\n",
        "import pandas as pd\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize(400),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "dataset = Dataset(\n",
        "    \"s3://eto-public/datasets/coco/coco.lance\",\n",
        "    columns=[\"image\", \"split\", \"image_id\"],\n",
        "    # mode=\"batch\",\n",
        "    batch_size=8)\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "  for batch in dataset:\n",
        "    image_id = batch[2].cpu().item()\n",
        "    imgs = [transform(batch[0]).cuda()]\n",
        "    # print(batch, batch.shape)\n",
        "    output = model(imgs)\n",
        "    output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]\n",
        "    mask = output[\"scores\"] > threshold\n",
        "    pred = {\n",
        "        \"image_id\": image_id,\n",
        "        \"boxes\": output[\"boxes\"][mask].cpu().numpy(),\n",
        "        \"labels\": output[\"labels\"][mask].cpu().numpy(),\n",
        "        \"scores\": output[\"scores\"][mask].cpu().numpy(),\n",
        "    }\n",
        "    del output\n",
        "    results.append(pred)\n",
        "\n",
        "df = pd.DataFrame(data=results)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "p66vbzcW5uhO",
        "outputId": "2dc99199-6200-4083-c362-f9a32846d40e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/DINO/models/dino/position_encoding.py:95: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_tx = self.temperatureW ** (2 * (dim_tx // 2) / self.num_pos_feats)\n",
            "/content/DINO/models/dino/position_encoding.py:99: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_ty = self.temperatureH ** (2 * (dim_ty // 2) / self.num_pos_feats)\n",
            "/content/DINO/models/dino/utils.py:156: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_t = 10000 ** (2 * (dim_t // 2) / 128)\n",
            "/content/DINO/models/dino/dino.py:680: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  topk_boxes = topk_indexes // out_logits.shape[2]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cf7ad93c2450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# print(batch, batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scores\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DINO/models/dino/dino.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, samples, targets)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0minput_query_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_query_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdn_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_box_proposal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_query_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_query_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;31m# In case num object=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DINO/models/dino/deformable_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, srcs, masks, refpoint_embed, pos_embeds, tgt, attn_mask)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Begin Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m#########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         hs, references = self.decoder(\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DINO/models/dino/deformable_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, pos, refpoints_unsigmoid, level_start_index, spatial_shapes, valid_ratios)\u001b[0m\n\u001b[1;32m    733\u001b[0m                     \u001b[0mdropflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdropflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 output = layer(\n\u001b[0m\u001b[1;32m    736\u001b[0m                     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                     \u001b[0mtgt_query_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DINO/models/dino/deformable_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, tgt_query_pos, tgt_query_sine_embed, tgt_key_padding_mask, tgt_reference_points, memory, memory_key_padding_mask, memory_level_start_index, memory_spatial_shapes, memory_pos, self_attn_mask, cross_attn_mask)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_ffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfuncname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ca'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                 tgt = self.forward_ca(tgt, tgt_query_pos, tgt_query_sine_embed, \\\n\u001b[0m\u001b[1;32m   1019\u001b[0m                     \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_reference_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m                         \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_level_start_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DINO/models/dino/deformable_transformer.py\u001b[0m in \u001b[0;36mforward_ca\u001b[0;34m(self, tgt, tgt_query_pos, tgt_query_sine_embed, tgt_key_padding_mask, tgt_reference_points, memory, memory_key_padding_mask, memory_level_start_index, memory_spatial_shapes, memory_pos, self_attn_mask, cross_attn_mask)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown key_aware_type: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_aware_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m         tgt2 = self.cross_attn(self.with_pos_embed(tgt, tgt_query_pos).transpose(0, 1),\n\u001b[0m\u001b[1;32m    987\u001b[0m                                \u001b[0mtgt_reference_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                                memory.transpose(0, 1), memory_spatial_shapes, memory_level_start_index, memory_key_padding_mask).transpose(0, 1)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DINO/models/dino/ops/modules/ms_deform_attn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, reference_points, input_flatten, input_spatial_shapes, input_level_start_index, input_padding_mask)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLen_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLen_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_flatten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_spatial_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_spatial_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLen_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_flatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}