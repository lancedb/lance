{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6fdcc6-01e1-4abc-9b6a-baa42bdc7aec",
   "metadata": {},
   "source": [
    "# ImageNet-1K Data Quality and Model Performance\n",
    "\n",
    "[ImageNet 1K dataset](https://www.image-net.org/index.php) is an established image classification dataset.\n",
    "Plenty of the off-shief classification models are trained on it.\n",
    "\n",
    "In this notebook, we demo how much more we can know from such a public dataset and models.\n",
    "\n",
    "First, let's load necessary packages and setup DuckDB extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a10997a-1786-4349-a290-61a10df983c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lance\n",
    "import duckdb\n",
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4f6c53-4700-4a66-937c-c7181ce8fea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            debugger;\n",
       "            let codeCell = (window.Jupyter ?? window.IPython)?.CodeCell;\n",
       "            if (codeCell) {\n",
       "                let highlightModes = (codeCell.options_default ?? codeCell.config_defaults).highlight_modes;\n",
       "                if (!highlightModes['magic_sql'])\n",
       "                    highlightModes['magic_sql'] = {'reg': []};\n",
       "                highlightModes['magic_sql']['reg'].push(/^%%sql/);\n",
       "            }\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql duckdb:///:memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269b8739-0396-4e61-8a1b-63b3570dee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"imagenet.lance\"\n",
    "\n",
    "ds = lance.dataset(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e17dd1-3669-4ced-acb8-9334f4dbacd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id: int32\n",
       "image: extension<image[binary]<ImageBinaryType>>\n",
       "label: int16\n",
       "name: dictionary<values=string, indices=int16, ordered=0>\n",
       "split: dictionary<values=string, indices=int8, ordered=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f82b63c-3d48-43e0-92cd-bca457184770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.005626678466796875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>count(split)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        split  count(split)\n",
       "0       train         10000\n",
       "1        test         10000\n",
       "2  validation         10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT split, count(split) FROM ds GROUP BY split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88265369-1d77-49bf-8af1-9cd9d8760201",
   "metadata": {},
   "source": [
    "## Use two official pre-trained models ResNet and VisionTransform\n",
    "\n",
    "We load two pretrained classic CNN and Transformer models to help us understand the dataset better.\n",
    "\n",
    "* The ResNet model is based on the [Deep Residual Learning for Image Recognition paper](https://arxiv.org/abs/1512.03385)\n",
    "* The VisionTransformer model is based on the [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale paper](https://arxiv.org/abs/2010.11929).\n",
    "\n",
    "Models are moved to the accelerators if available. \n",
    "Not only we support CUDA as backend, we support [MPS backend on macOS](https://pytorch.org/docs/stable/notes/mps.html) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c6619-0505-4e4a-8f57-59cf6740ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, vit_b_16\n",
    "import torch\n",
    "\n",
    "# Support CUDA (Linux) or MPS (Mac) backends.\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else (\n",
    "        \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "resnet = resnet50(weights=\"DEFAULT\").to(device)\n",
    "vit = vit_b_16(weights=\"DEFAULT\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e701a-337b-4f56-af4d-cea0a9f58411",
   "metadata": {},
   "source": [
    "## Run the inference of these two models\n",
    "\n",
    "And persist the predictions back to the dataset for future analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10acce-0334-4468-9835-29fdb1e2a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make easy conversion between lance.Dataset and lance.pytorch.Dataset\n",
    "from lance.pytorch import Dataset\n",
    "\n",
    "def run_inference(uri: str, model, transform, col_name: str) -> pa.Table:\n",
    "    dataset = Dataset(\n",
    "        uri, \n",
    "        columns=[\"id\", \"image\"],\n",
    "        mode=\"batch\",\n",
    "        batch_size=128\n",
    "    )\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in dataset:\n",
    "            imgs = [transform(img).to(device) for img in batch[1]]\n",
    "            prediction = resnet(torch.stack(imgs)).squeeze(0).softmax(0)\n",
    "            topk = torch.topk(prediction, 2)\n",
    "            for pk, scores, indices in zip(\n",
    "                batch[0], topk.values.tolist(), topk.indices.tolist()\n",
    "            ):\n",
    "                results.append({\n",
    "                    \"id\": pk.item(),\n",
    "                    col_name: {\n",
    "                        \"label\": indices[0], \n",
    "                        \"score\": scores[0], \n",
    "                        \"second_label\": indices[1],  # Secondary guess\n",
    "                        \"second_score\": scores[1],  # Confidence of the secondary guess.\n",
    "                    }\n",
    "                })\n",
    "    df = pd.DataFrame(data=results)\n",
    "    df = df.astype({\"id\": \"int32\"})\n",
    "    return pa.Table.from_pandas(df)\n",
    "\n",
    "resnet_table = run_inference(\n",
    "    uri, resnet, torchvision.models.ResNet50_Weights.DEFAULT.transforms(), \"resnet\"\n",
    ")\n",
    "vit_table = run_inference(\n",
    "    uri, vit, torchvision.models.ViT_L_16_Weights.DEFAULT.transforms(), \"vit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f0a06-63bf-48f1-a4cb-c9f2af9ca249",
   "metadata": {},
   "source": [
    "### Adding the inference results back to the dataset via appending columns.\n",
    "\n",
    "Because Lance supports [Schema Evolution](https://en.wikipedia.org/wiki/Schema_evolution), \n",
    "it is quite easy and fast to add new columns each time for one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33626633-2817-4574-b688-96b93acfb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.merge(resnet_table, left_on=\"id\", right_on=\"id\")\n",
    "ds = ds.merge(vit_table, left_on=\"id\", right_on=\"id\")\n",
    "ds.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01765557-90a1-4a6f-b5d0-50c03e4c394e",
   "metadata": {},
   "source": [
    "As a result, two columns `resnet` and `vit` are added using a LEFT JOIN algorithm on the \"id\" column, each of which contains the inference output from the model respectively.\n",
    "\n",
    "Actually, by doing so, we creates 2 extra versions of Lance dataset. Underneath, Lance only writes the new columns to disk. It will not make extra copy of the existing columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c19ab-1e71-4ffb-b7ed-f569a71160ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See multiple versions of the dataset\n",
    "\n",
    "ds.versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db710fb-5099-4c99-a491-8d08db775d56",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "Using lance and SQL, computing basic ML metrics such as precision is straightfoward and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb32c1a-a7cb-4f74-b99e-e5b6e5c263b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT \n",
    "  SUM(CAST(resnet.label == label AS FLOAT)) / COUNT(label) as resnet_precision,\n",
    "  SUM(CAST(vit.label == label AS FLOAT)) / COUNT(label) as vit_precision\n",
    "FROM ds \n",
    "WHERE split = 'validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2708e8-c65a-4335-94c3-cf01f4700451",
   "metadata": {},
   "source": [
    "Using DuckDB / SQL, it is trivial to slice into each label class to see model performance in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1171c-1916-4ffa-b03e-e1f411fd8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT\n",
    "  DISTINCT(name),\n",
    "  SUM(CAST(resnet.label == label AS FLOAT)) / COUNT(label) as resnet_precision,\n",
    "  SUM(CAST(vit.label == label AS FLOAT)) / COUNT(label) as vit_precision\n",
    "FROM ds \n",
    "WHERE split = 'validation'\n",
    "GROUP BY name\n",
    "ORDER BY resnet_precision ASC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a076b94-9591-4d6e-9191-45c77894e42e",
   "metadata": {},
   "source": [
    "## Find Potential Mislabels\n",
    "\n",
    "If the two models strongly agree with each other (i.e., same label and confience score is high), however, the predict label is not what ground truth describes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10054526-3359-46e2-975b-4ec2215174d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "WITH label_names AS (SELECT DISTINCT label, name FROM ds)\n",
    "\n",
    "SELECT ds.name AS gt, ds.label as gt_label,\n",
    "  resnet.label as resnet_label,\n",
    "  vit.label as vit_label,\n",
    "  label_names.name as predict_name,\n",
    "  resnet.score as predict_score\n",
    "FROM ds, label_names \n",
    "WHERE\n",
    "  split != 'test'\n",
    "  AND ds.label !=  resnet.label \n",
    "  AND resnet.label == vit.label\n",
    "  AND resnet.label = label_names.label\n",
    "ORDER BY resnet.score DESC\n",
    "LIMIT 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bee41-6758-41ee-91c2-caab81e8e4ae",
   "metadata": {},
   "source": [
    "The reverse order of the above query (`ORDER BY score ASC`) is also very informative, \n",
    "as it shows where the weak agreement cross different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf1557-55c0-4d05-8064-3a37123aca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "WITH label_names AS (SELECT DISTINCT label, name FROM ds)\n",
    "\n",
    "SELECT ds.name AS gt, ds.label as gt_label,\n",
    "  resnet.label as resnet_label,\n",
    "  vit.label as vit_label,\n",
    "  label_names.name as predict_name,\n",
    "  resnet.score as resnet_score,\n",
    "  vit.score as vit_score\n",
    "FROM ds, label_names \n",
    "WHERE\n",
    "  split != 'test'\n",
    "  AND ds.label !=  resnet.label \n",
    "  AND resnet.label == vit.label\n",
    "  AND resnet.label = label_names.label\n",
    "ORDER BY resnet.score ASC\n",
    "LIMIT 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f0a0b-218d-4969-aa27-072667b09ce7",
   "metadata": {},
   "source": [
    "We can dig into the distribution to see which class behavor the worst. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7916568-78d7-42d9-9c7d-0e346cfcd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "WITH label_names AS (SELECT DISTINCT label, name FROM ds)\n",
    "\n",
    "SELECT\n",
    "  DISTINCT label_names.name as name,\n",
    "  COUNT(label_names.name) as cnt,\n",
    "  AVG(resnet.score) as avg_score\n",
    "FROM ds, label_names \n",
    "WHERE\n",
    "  split != 'test'\n",
    "  AND ds.label !=  resnet.label \n",
    "  AND resnet.label == vit.label\n",
    "  AND resnet.label = label_names.label\n",
    "  AND resnet.score < 0.35\n",
    "GROUP BY 1\n",
    "ORDER BY 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ce794-5cbe-4a46-898f-f7be84cd93aa",
   "metadata": {},
   "source": [
    "## Active Learning in Lance\n",
    "\n",
    "With Lance and DuckDB, it is easy to build active learning loop as well.\n",
    "\n",
    "One typical approach of Active Learning is finding `Lowest Margin of Confidence`. \n",
    "\n",
    "This query finds the examples where a model (*ResNet* in this case) is less confident between the top two candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad7b95-af4d-4cea-af23-c387a79c3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "WITH label_names AS (SELECT DISTINCT label, name FROM ds)\n",
    "\n",
    "SELECT \n",
    "    id, \n",
    "    ds.label as gt_label, \n",
    "    ds.name as gt,\n",
    "    n1.name as best_guess,\n",
    "    n2.name as second_guess,\n",
    "    resnet.score - resnet.second_score AS margin_of_confidence\n",
    "FROM ds, label_names as n1, label_names as n2\n",
    "WHERE \n",
    "    split != 'test'\n",
    "    AND n1.label = resnet.label\n",
    "    AND n2.label = resnet.second_label\n",
    "ORDER BY margin_of_confidence\n",
    "LIMIT 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015fcf8-5b06-46de-98f3-e3a11c0be061",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
